{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# from ocr_legal.search_engine.functions import create_index, add_documents_to_index\n",
    "#\n",
    "# create_index(\"index\")\n",
    "# add_documents_to_index(\"index\", \"data/ocr/ocr_documents.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from whoosh.index import open_dir\n",
    "\n",
    "ix = open_dir('index')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "searcher = ix.searcher()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/ocr/ocr_documents.csv')\n",
    "print(df.loc[6]['body'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09112900965\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "\n",
    "qp = QueryParser(\"content\", schema=ix.schema)\n",
    "q = qp.parse(u\"software\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    results = s.search(q)\n",
    "    print(results[0]['title'])\n",
    "    #for hit in results:\n",
    "    #     print(hit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b9623b615f54d01897cfe57a29cbd99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/984k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f893274133f648e0910d30ff8e4eb2b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.74k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c034b05bf124bda89b0f6463c9c11ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"gsarti/it5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gsarti/it5-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "sentence = '''\n",
    "ARTICOL\n",
    "L'oggetto della Società è di svilu\n",
    "informatiche (software), di hardwa\n",
    "delle tecnologie convergenti (che\n",
    "l'incorporazione di circuiti elettro\n",
    "congiuntamente con dei tessili (tess\n",
    "e/o dei beni durevoli (come,\n",
    "                       intrattenimento/dei beni di eq\n",
    "braccialetti).\n",
    "'''\n",
    "\n",
    "tokens = tokenizer.encode(sentence, return_tensors='pt')\n",
    "output = model.generate(tokens, max_length=256)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "PipelineException",
     "evalue": "The tokenizer does not define a `mask_token`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPipelineException\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[0;32m----> 3\u001B[0m unmasker \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfill-mask\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgsarti/it5-base\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/management/work/progetto_se/OCR-legal/venv/lib/python3.10/site-packages/transformers/pipelines/__init__.py:684\u001B[0m, in \u001B[0;36mpipeline\u001B[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001B[0m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m feature_extractor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    682\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature_extractor\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m feature_extractor\n\u001B[0;32m--> 684\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpipeline_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframework\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mframework\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/management/work/progetto_se/OCR-legal/venv/lib/python3.10/site-packages/transformers/pipelines/base.py:780\u001B[0m, in \u001B[0;36mPipeline.__init__\u001B[0;34m(self, model, tokenizer, feature_extractor, modelcard, framework, task, args_parser, device, binary_output, **kwargs)\u001B[0m\n\u001B[1;32m    778\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_size \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    779\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_workers \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_workers\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 780\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preprocess_params, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_params, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_postprocess_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sanitize_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/management/work/progetto_se/OCR-legal/venv/lib/python3.10/site-packages/transformers/pipelines/fill_mask.py:200\u001B[0m, in \u001B[0;36mFillMaskPipeline._sanitize_parameters\u001B[0;34m(self, top_k, targets)\u001B[0m\n\u001B[1;32m    197\u001B[0m     postprocess_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_k\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m top_k\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mmask_token_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 200\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PipelineException(\n\u001B[1;32m    201\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfill-mask\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mbase_model_prefix, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe tokenizer does not define a `mask_token`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    202\u001B[0m     )\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {}, {}, postprocess_params\n",
      "\u001B[0;31mPipelineException\u001B[0m: The tokenizer does not define a `mask_token`."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\", model = \"gsarti/it5-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "\"della società è di svilu informatiche della società dellasoftware), di hardwa delle tecnologie convergenti (software) (software) della società... l'oggetto della società l'oggetto della... \""
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_string = tokenizer.decode(output[0],\n",
    "                                 skip_special_tokens=True)\n",
    "output_string"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/management/work/progetto_se/OCR-legal/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/jack/Desktop/management/work/progetto_se/OCR-legal/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/mindee/doctr/releases/download/v0.3.1/db_resnet50-ac60cadc.pt to /home/jack/.cache/doctr/models/db_resnet50-ac60cadc.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/101971449 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7213ef25b8a4486588c2542092b16760"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/mindee/doctr/releases/download/v0.3.1/crnn_vgg16_bn-9762b0b0.pt to /home/jack/.cache/doctr/models/crnn_vgg16_bn-9762b0b0.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/63286381 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "605a6c78e57a4d5ca19daa714f636dd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pypdfium2' has no attribute 'render_pdf_topil'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m ocr_predictor(pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# PDF\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m doc \u001B[38;5;241m=\u001B[39m \u001B[43mDocumentFile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pdf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/STATUTI NON OCRd/09976850967.pdf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Analyze\u001B[39;00m\n\u001B[1;32m      8\u001B[0m result \u001B[38;5;241m=\u001B[39m model(doc)\n",
      "File \u001B[0;32m~/Desktop/management/work/progetto_se/OCR-legal/venv/lib/python3.10/site-packages/doctr/io/reader.py:37\u001B[0m, in \u001B[0;36mDocumentFile.from_pdf\u001B[0;34m(cls, file, **kwargs)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_pdf\u001B[39m(\u001B[38;5;28mcls\u001B[39m, file: AbstractFile, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;124;03m\"\"\"Read a PDF file\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03m    >>> from doctr.documents import DocumentFile\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03m        the list of pages decoded as numpy ndarray of shape H x W x 3\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mread_pdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/management/work/progetto_se/OCR-legal/venv/lib/python3.10/site-packages/doctr/io/pdf.py:42\u001B[0m, in \u001B[0;36mread_pdf\u001B[0;34m(file, scale, **kwargs)\u001B[0m\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munable to access \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Rasterise pages to PIL images with pypdfium2 and convert to numpy ndarrays\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [np\u001B[38;5;241m.\u001B[39masarray(img) \u001B[38;5;28;01mfor\u001B[39;00m img, _ \u001B[38;5;129;01min\u001B[39;00m \u001B[43mpdfium\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender_pdf_topil\u001B[49m(file, scale\u001B[38;5;241m=\u001B[39mscale, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'pypdfium2' has no attribute 'render_pdf_topil'"
     ]
    }
   ],
   "source": [
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "model = ocr_predictor(pretrained=True)\n",
    "# PDF\n",
    "doc = DocumentFile.from_pdf(\"data/STATUTI NON OCRd/09976850967.pdf\")\n",
    "# Analyze\n",
    "result = model(doc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.loc[6]['body'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}